# ðŸ§¥ YOLOv11 Transfer Learning for Clothes Detection

This project applies **transfer learning** on the YOLOv11 (Ultralytics YOLOv8-compatible) object detection model to classify and localize 18 categories of clothing. The model was fine-tuned on a custom-labeled apparel dataset, achieving strong performance on unseen test images.

---

## ðŸ“Œ Project Overview

- **Base Model**: YOLOv11 (`yolov11n.pt`)
- **Task**: Object detection of fine-grained clothing types
- **Dataset**: 9,517 images (train: 7,482 / val: 1,016 / test: 1,019)
- **Classes**: 18 clothing categories (e.g., hoodie, blazer, cardigan, etc.)
- **Format**: YOLOv5-compatible dataset structure
- **Tools**: Ultralytics CLI, PyTorch, Roboflow

---

## ðŸ—‚ Dataset Structure

```
clothes_dataset/
â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ val/
â”‚ â””â”€â”€ test/
â”œâ”€â”€ labels/
â”‚ â”œâ”€â”€ train/
â”‚ â”œâ”€â”€ val/
â”‚ â””â”€â”€ test/
â””â”€â”€ data.yaml
```

- Each `.txt` label file follows the format: class_id x_center y_center width height # all values normalized (0~1)


---

## ðŸ§ª Classes

```yaml
names: ['blazer', 'cardigan', 'coat', 'cottonpants', 'denimpants', 'hoodies', 'jacket', 'longsleeve', 'mtm', 'padding', 'shirt', 'shortpants', 'shortsleeve', 'skirt', 'slacks', 'sweater', 'trainingpants', 'zipup']

```

---

## ðŸš€ Training Command
yolo train \
  model=yolov11n.pt \
  data=clothes_dataset/data.yaml \
  epochs=50 \
  imgsz=640 \
  batch=16 \
  name=clothing_yolov11


## ðŸ“ˆ Evaluation
yolo val \
  model=runs/detect/clothing_yolov11/weights/best.pt \
  data=clothes_dataset/data.yaml \
  split=test

ðŸ”¹ Evaluation Results
Â Â Â Â The trained model was evaluated using a combination of quantitative metrics and visual analysis.
Â Â Â Â This section summarizes the key outcomes from the evaluation phase.

ðŸ”¹ Confusion Matrix Analysis
Â Â Â Â To evaluate inter-class confusion, both the absolute and normalized confusion matrices were analyzed:

Â Â Â Â â€¢ Most predictions align well along the diagonal, indicating strong classification accuracy.
Â Â Â Â â€¢ High accuracy was observed for classes such as shortpants, shortsleeve, and denimpants.
Â Â Â Â â€¢ Some confusion was noted among visually similar categories, such as jacket, cardigan, sweater, and longsleeve.

Â Â Â Â Image 1 â€“ Confusion Matrix (absolute counts)
Â Â Â Â Image 2 â€“ Normalized Confusion Matrix (proportions)

ðŸ”¹ Confidence-Based Metric Curves
Â Â Â Â Confidence-based evaluation curves were plotted to understand how the model behaves across different confidence thresholds:

Â Â Â Â â€¢ Most classes show stable precision and recall in the confidence range of 0.7â€“0.9.
Â Â Â Â â€¢ shortsleeve and shortpants achieved exceptionally high scores across all confidence levels.
Â Â Â Â â€¢ On the other hand, zipup showed lower performance, likely due to visual overlap with similar items and data scarcity.

Â Â Â Â Image 3 â€“ Precision vs. Confidence Curve
Â Â Â Â Image 4 â€“ F1 Score vs. Confidence Curve
Â Â Â Â Image 5 â€“ Recall vs. Confidence Curve
Â Â Â Â Image 6 â€“ Precision-Recall Curve + mAP@0.5 (0.744)

ðŸ”¹ Label Distribution and Bounding Box Analysis
Â Â Â Â We also analyzed the label frequency distribution and spatial characteristics of bounding boxes:

Â Â Â Â â€¢ denimpants, shortpants, and shortsleeve appeared frequently in the dataset, which correlates with their strong detection performance.
Â Â Â Â â€¢ Bounding boxes are densely centered in the image frame, and their size distribution shows a healthy variety, reducing risk of spatial bias.

Â Â Â Â Image 7 â€“ Class frequency histogram + bbox heatmaps (x/y/width/height)
Â Â Â Â Image 8 â€“ Bounding box correlation plots (Correlogram)

ðŸ”¹ Summary of Model Performance
Â Â Â Â â€¢ The model achieved a mean Average Precision (mAP@0.5) of 0.744 across all classes.
Â Â Â Â â€¢ shortpants, shortsleeve, and skirt demonstrated the most robust performance, suggesting practical application potential.
Â Â Â Â â€¢ Confusion among jacket-type garments suggests future improvements could involve fine-grained loss functions or more specialized model architectures.

ðŸ”¹ Batch-wise Prediction vs Ground Truth (Visual Analysis)
Â Â Â Â To complement numerical evaluation, we visualized prediction results for randomly sampled training and validation batches:

Â Â Â Â Figure 2.1.5a: train_batch0.jpg to train_batch21062.jpg show ground truth annotations in the training set.
Â Â Â Â Figure 2.1.5b: val_batch0_labels.jpg, val_batch1_labels.jpg, val_batch2_labels.jpg show validation ground truth labels.
Â Â Â Â Figure 2.1.5c: val_batch0_pred.jpg, val_batch1_pred.jpg, val_batch2_pred.jpg display model predictions for the same validation samples.

Â Â Â Â Key Observations:
Â Â Â Â â€¢ The model shows consistent performance across batches, especially for frequent classes like shortpants, skirt, and cottonpants.
Â Â Â Â â€¢ Confidence scores are generally high, often exceeding 0.85 for clean, well-lit samples (e.g., shortsleeve: 0.93, blazer: 0.97).
Â Â Â Â â€¢ Rare classes like zipup or padding show lower prediction confidence and are occasionally confused with visually similar categories, reflecting the class imbalance noted in the training distribution.

ðŸ”¹ False Positive / False Negative Examples (Qualitative Errors)
Â Â Â Â The added figure (ff2dbe3f-bf0a-4bbc-b704-21ad9ca3ea46.jpg) demonstrates common misclassification patterns:

Â Â Â Â â€¢ False Positives: Bounding boxes predicted for garments not present in ground truth, often caused by overlapping or ambiguous clothing views (e.g., shortpants vs. skirt).
Â Â Â Â â€¢ False Negatives: Some garments annotated in the ground truth were completely missed â€” especially darker or partially occluded items (e.g., hoodie under jacket).

Â Â Â Â This analysis suggests the need for improved post-processing and better threshold tuning in deployment.

ðŸ”¹ Label-Prediction Match Consistency
Â Â Â Â A side-by-side review of val_batch*_labels.jpg and val_batch*_pred.jpg showed:

Â Â Â Â â€¢ High spatial consistency in predicted bounding boxes (visually aligned with ground truth).
Â Â Â Â â€¢ Moderate confusion between semantically similar categories like cardigan vs. jacket, and slacks vs. cottonpants.
Â Â Â Â â€¢ Emphasizes the need for consistent annotation guidelines when dealing with fine-grained apparel classes.

ðŸ”¹ Overall Evaluation Summary
Â Â Â Â The combination of quantitative and qualitative evaluation suggests the YOLO-based clothing detection model is effective across most categories.

Â Â Â Â Strengths:
Â Â Â Â â€¢ Strong generalization in diverse images (pose, lighting, occlusion).
Â Â Â Â â€¢ mAP@0.5 = 0.744 with especially high scores on shortsleeve, shortpants, and skirt.
Â Â Â Â â€¢ High confidence detection for common classes.

Â Â Â Â Limitations:
Â Â Â Â â€¢ Frequent misclassification between similar garments (e.g., jacket vs. cardigan).
Â Â Â Â â€¢ Weak performance on rare or ambiguous classes like zipup, padding.

Â Â Â Â Recommendations:
Â Â Â Â â€¢ Incorporate fine-grained losses or hierarchical class structures.
Â Â Â Â â€¢ Apply focal loss or class reweighting for imbalance.
Â Â Â Â â€¢ Consider vision-language models (e.g., OWL-ViT, YOLO-World) for open-vocabulary detection.


## ðŸ“· Real-time Detection by webcam
To test the trained model in real time using your laptop's webcam:

1. Install dependencies
  Make sure you have installed all required packages:
  ```
  pip install -r requirements.txt
  ```
2. Run the script
  Execute the following command in your terminal:
  ```
  python run_yolov11_webcam.py
  ```
3. Usage
  - A window will open showing your webcam feed with real-time bounding boxes and class labels.
  - Press q to close the window and stop the program.

Note:
  - The webcam index (0) is set for the default laptop camera. Change it to 1 or another index if you use an external camera.
  - Make sure the model weights path in the script matches your actual file location.


## ðŸ–¼ Inference
yolo predict \
  model=runs/detect/clothing_yolov11/weights/best.pt \
  source=clothes_dataset/images/test \
  save=True


## ðŸ“š Reference
Ultralytics YOLOv11 GitHub

Roboflow Dataset Tools
